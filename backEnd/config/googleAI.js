const fs = require("fs");
const { google } = require("googleapis");
const { GoogleGenerativeAI } = require("@google/generative-ai");
const { GoogleAIFileManager } = require("@google/generative-ai/server");
require("dotenv").config();
const { uploadFile } = require("./googleDrive");

// Initialize Gemini AI
const genAI = new GoogleGenerativeAI(process.env.GEMINI_API_KEY);
const fileManager = new GoogleAIFileManager(process.env.GEMINI_API_KEY);
const model = genAI.getGenerativeModel({ model: "gemini-2.0-flash" });
console.log("Initialized Gemini Model:", "gemini-2.0-flash");

// Evaluate Assignment using Gemini AI
const evaluateAssignment = async (filePath, mimeType, questionText, expectedAnswer) => {
    try {
        const uploadResult = await fileManager.uploadFile(filePath, {
            mimeType,
            displayName: "Assignment Evaluation",
        });

        const result = await model.generateContent([
            {
                fileData: {
                    fileUri: uploadResult.file.uri,
                    mimeType: uploadResult.file.mimeType,
                },
            },
            `Evaluate the student's answer based on the given question and provide a structured assessment.

Question: "${questionText}"
${expectedAnswer ? `Expected Answer / Key Points: "${expectedAnswer}"` : ""}

Ensure that:

Relevance Check:
If a diagram is required for the question but is not found in the assignment, ask the student to include it.
Identify any missing concepts or areas that need correction. Highlight any inaccuracies or improvements needed for better understanding and completeness.
Determine if the student's answer directly addresses the given question.
If the answer is unrelated or incorrect, provide specific feedback explaining the issue.

Constructive Feedback:
Assess the correctness, clarity, and completeness of the response.
Highlight strengths, pinpoint errors, and suggest improvements.

Marks Allocation:
Assign marks based on accuracy, depth, and quality of the response.
Clearly justify the awarded marks with constructive comments.

Plagiarism Detection:
Check for plagiarism and include a plagiarism score in the evaluation.

AI-Generated Answer Detection:
If the answer is AI-generated:
Set isAIGenerated to true.
Set totalMarks to 0.
Provide a comment in aiGeneratedFeedback stating:
"Your submission appears to be generated by AI. Your marks have been set to 0. Please write the answer in your own words and resubmit it."

Student's Answer:
(Extract answer from the submitted file)

Respond strictly in valid JSON format with no extra text or formatting:

{
"Question": "${questionText}",
"isRelevant": true,
"relevanceFeedback": "Explain in one sentence whether the answer is relevant to the question.",
"feedback": [
"Pointwise feedback on the answer",
"Highlight errors or missing aspects",
"Provide suggestions for improvement"
],
"marksPerQuestion": [
{
"questionId": "${questionText}",
"marksAwarded": 0,
"reasonForDeduction": "Explain specifically why marks were deducted (e.g., 'Missing explanation of X', 'Incorrect formula used'). If full marks, write 'None'.",
"missingPoints": "List specific technical terms, concepts, or steps that are missing. Example: 'Missing B-tree, GIN index, and GiST index'. Be precise. If full marks, write 'None'.",
"comments": "Constructive feedback summarizing strengths and specifically naming missing elements."
}
],
"totalMarks": 0,
"plagiarismScore": 0,
"isAIGenerated": false,
"aiGeneratedFeedback": ""
}

Note:
1. **CRITICAL**: You must CALCULATE the "marksAwarded" and "totalMarks" based on the correctness and depth of the student's answer. Do NOT simply copy the 0 from the example above.
2. If the answer is AI-generated:
   - Set "isAIGenerated" to true.
   - Set "totalMarks" to 0.
   - Set "marksAwarded" in "marksPerQuestion" to 0 with a comment: "No marks awarded due to AI-generated content."
   - Set "aiGeneratedFeedback" to: "Your submission appears to be generated by AI. Your marks have been set to 0. Please write the answer in your own words and resubmit it."
`,
        ]);
        const responseText = await result.response.text();
        console.log("questionText:  ", questionText);
        return responseText;
    } catch (error) {
        console.error("Evaluation Error:", error);
        throw error;
    }
};

module.exports = { evaluateAssignment }